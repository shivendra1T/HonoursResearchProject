{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdb8c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from docx import Document\n",
    "from textblob import TextBlob\n",
    "import nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f45f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure necessary NLTK corpora are downloaded\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ddb9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_docx(file_path):\n",
    "    \"\"\"Reads all text from a .docx file.\"\"\"\n",
    "    doc = Document(file_path)\n",
    "    full_text = []\n",
    "    for para in doc.paragraphs:\n",
    "        full_text.append(para.text)\n",
    "    return '\\n'.join(full_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39772e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_docx(text, output_path):\n",
    "    \"\"\"Writes cleaned text to a .docx file.\"\"\"\n",
    "    doc = Document()\n",
    "    for paragraph in text.split('\\n'):\n",
    "        doc.add_paragraph(paragraph)\n",
    "    doc.save(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22897b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_metadata_and_watermarks(text):\n",
    "    \"\"\"Remove common AI watermark and metadata patterns.\"\"\"\n",
    "    watermark_patterns = [\n",
    "        r\"This content was generated by.*?\\.\",       # Common disclaimers\n",
    "        r\"Generated by ChatGPT.*?\\.\",               # AI model mentions\n",
    "        r\"OpenAI.*?\\.\",                             # Brand mentions\n",
    "        r\"AI-generated content\",                    # Generic terms\n",
    "        r\"\\[\\d{4}-\\d{2}-\\d{2}.*?\\]\",                # Date/time patterns\n",
    "    ]\n",
    "    for pattern in watermark_patterns:\n",
    "        text = re.sub(pattern, '', text, flags=re.IGNORECASE | re.MULTILINE)\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9801287e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def humanize_text(text):\n",
    "    \"\"\"Attempts to humanize AI-like patterns.\"\"\"\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    naturalized = []\n",
    "    for sentence in sentences:\n",
    "        blob = TextBlob(sentence)\n",
    "        # Rewriting with slight variation (correction, casual tone)\n",
    "        corrected = blob.correct()\n",
    "        # Add a touch of variation\n",
    "        if len(corrected.words) > 5:\n",
    "            corrected = corrected.replace(\"This is\", \"Here's\") \\\n",
    "                                 .replace(\"It is\", \"It's\") \\\n",
    "                                 .replace(\"Do not\", \"Don't\")\n",
    "        naturalized.append(str(corrected))\n",
    "    return ' '.join(naturalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78effc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_humanize_doc(input_path, output_path):\n",
    "    \"\"\"Main pipeline to clean and rewrite document content.\"\"\"\n",
    "    try:\n",
    "        print(\"Reading document...\")\n",
    "        text = read_docx(input_path)\n",
    "        \n",
    "        print(\"Removing metadata and watermarks...\")\n",
    "        cleaned = remove_metadata_and_watermarks(text)\n",
    "        \n",
    "        print(\"Humanizing text...\")\n",
    "        humanized = humanize_text(cleaned)\n",
    "        \n",
    "        print(\"Writing final document...\")\n",
    "        write_docx(humanized, output_path)\n",
    "\n",
    "        print(f\"Done! Cleaned document saved at: {output_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9c0f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== RUNNING EXAMPLE ==========\n",
    "if __name__ == \"__main__\":\n",
    "    input_docx = \"input.docx\"   # Replace with your actual input file\n",
    "    output_docx = \"cleaned_output.docx\"\n",
    "    clean_and_humanize_doc(input_docx, output_docx)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
